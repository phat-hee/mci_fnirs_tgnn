{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from glob import glob\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def quadratic(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "def detect_smile_or_sad_shape(data, threshold=0.7):\n",
    "    x = np.linspace(0, 1, len(data))\n",
    "    try:\n",
    "        popt, _ = curve_fit(quadratic, x, data)\n",
    "        a = popt[0]\n",
    "        r_squared = 1 - (np.sum((data - quadratic(x, *popt))**2) / np.sum((data - np.mean(data))**2))\n",
    "\n",
    "        if r_squared > threshold:\n",
    "            return True if a != 0 else False\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def collect_all_data(directory, all_data):\n",
    "    for filename in glob(os.path.join(directory, '*.mat')):\n",
    "        mat_data = sio.loadmat(filename)\n",
    "        corrected_data = mat_data['detrended_data']\n",
    "\n",
    "        if corrected_data.shape[1] != 48:\n",
    "            print(f\"Warning: Unexpected number of channels in {filename}. Shape: {corrected_data.shape}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing file: {filename}, Shape: {corrected_data.shape}\")\n",
    "\n",
    "        for channel in range(corrected_data.shape[1]):\n",
    "            if not detect_smile_or_sad_shape(corrected_data[:, channel]):\n",
    "                if channel not in all_data:\n",
    "                    all_data[channel] = []\n",
    "                all_data[channel].append(corrected_data[:, channel])\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def normalize_and_save_data(directory, max_values, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for filename in glob(os.path.join(directory, '*.mat')):\n",
    "        mat_data = sio.loadmat(filename)\n",
    "        corrected_data = mat_data['detrended_data']\n",
    "\n",
    "        if corrected_data.shape[1] != 48:\n",
    "            print(f\"Warning: Unexpected number of channels in {filename}. Shape: {corrected_data.shape}\")\n",
    "            continue\n",
    "\n",
    "        for channel in range(corrected_data.shape[1]):\n",
    "            corrected_data[:, channel] /= max_values[channel]\n",
    "\n",
    "        save_path = os.path.join(save_dir, os.path.basename(filename))\n",
    "        sio.savemat(save_path, {'corrected_data': corrected_data})\n",
    "        print(f\"Saved normalized data to: {save_path}\")\n",
    "\n",
    "# Base directory\n",
    "base_dir ='' ",
    "\n",
    "\n",
    "# Define subdirectories\n",
    "subdirs = {\n",
    "\n",
    "\n",
    "           'rest_hc' :'hc',\n",
    "           'rest_mci' : 'mci'\n",
    "    # 'stroop_mci': 'stroop_seg_mrg/baseline1_2/baseline1_2_onlydatas/MCI',\n",
    "    # 'stroop_hc': 'stroop_seg_mrg/baseline1_2/baseline1_2_onlydatas/HC',\n",
    "    # 'nback_mci': 'nback_seg_mrg/baseline1_2/baseline1_2_onlydatas/MCI',\n",
    "    # 'nback_hc': 'nback_seg_mrg/baseline1_2/baseline1_2_onlydatas/HC'\n",
    "}\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "# Collect all data\n",
    "for key, subdir in subdirs.items():\n",
    "    full_path = os.path.join(base_dir, subdir)\n",
    "    print(f\"Collecting data from: {full_path}\")\n",
    "    all_data = collect_all_data(full_path, all_data)\n",
    "\n",
    "# Find the maximum absolute value for each channel\n",
    "max_values = {}\n",
    "for channel, data in all_data.items():\n",
    "    max_values[channel] = np.max(np.abs(np.concatenate(data)))\n",
    "\n",
    "print(f\"Maximum absolute values for each channel: {max_values}\")\n",
    "\n",
    "# Normalize and save data\n",
    "save_base_dir = ''\n",
    "for key, subdir in subdirs.items():\n",
    "    full_path = os.path.join(base_dir, subdir)\n",
    "    if 'rest' in key:\n",
    "        if 'mci' in key:\n",
    "            save_dir = os.path.join(save_base_dir, 'rest', 'mci')\n",
    "        else:\n",
    "            save_dir = os.path.join(save_base_dir, 'rest', 'hc')\n",
    "\n",
    "    # if 'stroop' in key:\n",
    "    #     if 'mci' in key:\n",
    "    #         save_dir = os.path.join(save_base_dir, 'stroop', 'mci')\n",
    "    #     else:\n",
    "    #         save_dir = os.path.join(save_base_dir, 'stroop', 'hc')\n",
    "    # else:\n",
    "    #     if 'mci' in key:\n",
    "    #         save_dir = os.path.join(save_base_dir, 'nback', 'mci')\n",
    "    #     else:\n",
    "    #         save_dir = os.path.join(save_base_dir, 'nback', 'hc')\n",
    "\n",
    "    print(f\"Normalizing and saving data from: {full_path} to {save_dir}\")\n",
    "    normalize_and_save_data(full_path, max_values, save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
